[Run id]
datetime = 

[General]
n_iters = 2
WORKING_W = 256
WORKING_H = 256
CACHE_NAME = my_cache_dev_test
; for iter >1, what to choose as src 
; 1 - use initial experts
; 2 - use ensembles / updated experts
iters_config = 2

[Experts]
# 0. RGBModel(full_experts),
# 1. DepthModelXTC(full_experts),
# 2. SurfaceNormalsXTC(full_experts),
# 3. EdgesModel(full_experts),
# 4. SaliencySegmModel(full_experts),
# 5. HalftoneModel(full_experts, 0),
selector_map = 0, 2, 1, 3

[GraphStructure]
; restricted_graph_type [0/1/2/3] - 0 - no restriction => all experts from selector_map above
;                                 - 1 - keep only edges with source == restricted_graph_exp_identifier
;                                 - 2 - keep only edges with destination == restricted_graph_exp_identifier
;                                 - 3 - keep only edges with source == restricted_graph_exp_identifier or destination==restricted_graph_exp_identifier
restricted_graph_type = 3 
restricted_graph_exp_identifier = rgb

[PathsIter1]
; SPLIT can be TRAIN, VALID or TEST
; SPLIT_SRC_PATH = path_1
;       path_2
;       ...
;       path_n
; SPLIT_DST_PATH = path_1
;       path_2
;       ...
;       path_n
; SPLIT_PATTERNS = pattern_1
;       pattern_2 
;       ...
;       path_m
; m [1 or n] - if 1 => same pattern for all n input paths 
;            - if n => individual pattern for each of the n input paths 
;            - otherwise => multiple patterns for each of the n input paths 
; SPLIT_FIRST_K = nr
; nr - (-1) => all samples
;    - 0 => empty dataset 
;    - otherwise => nr samples
; for store purpose => will get first k from each subset
ITER1_TRAIN_SRC_PATH = /data/multi-domain-graph-3/datasets/datasets_preproc_exp/taskonomy/tiny-train_0.15/part1
    /data/multi-domain-graph-3/datasets/datasets_preproc_exp/taskonomy/tiny-train_0.15/part2
ITER1_TRAIN_DST_PATH = /data/multi-domain-graph-3/datasets/datasets_preproc_exp/taskonomy/tiny-train_0.15/part1
    /data/multi-domain-graph-3/datasets/datasets_preproc_exp/taskonomy/tiny-train_0.15/part2
ITER1_TRAIN_PATTERNS = /*
ITER1_TRAIN_FIRST_K = 100

ITER1_VALID_SRC_PATH = /data/multi-domain-graph-3/datasets/datasets_preproc_exp/taskonomy/tiny-val-ok
ITER1_VALID_DST_PATH = /data/multi-domain-graph-3/datasets/datasets_preproc_exp/taskonomy/tiny-val-ok
ITER1_VALID_PATTERNS = /*
ITER1_VALID_FIRST_K = 100

ITER1_TEST_SRC_PATH = /data/multi-domain-graph-3/datasets/datasets_preproc_exp/taskonomy/tiny-test-ok
ITER1_TEST_DST_PATH = /data/multi-domain-graph-3/datasets/datasets_preproc_exp/taskonomy/tiny-test-ok
ITER1_TEST_GT_DST_PATH = /data/multi-domain-graph-3/datasets/datasets_preproc_gt/taskonomy/tiny-test-ok
ITER1_TEST_PATTERNS = /*
ITER1_TEST_FIRST_K = 100

[PathsIter2]
; SPLIT can be TRAIN, VALID or TEST
; NEXT_ITER_SPLIT_STORE_PATH should have the same nr of elements as NEXT_ITER_SPLIT_SRC_PATH & NEXT_ITER_SPLIT_DST_PATH
; same conventions as for 'Paths'
; if NEXT_ITER_SPLIT_TYPE is empty => will get value of SPLIT_TYPE from 'Paths', for SPLIT in {TRAIN, VALID, TEST} and TYPE in {SRC_PATH, DST_PATH, PATTERNS, FIRST_K}
;    exception for TYPE=STORE_PATH - which is required 
ITER2_TRAIN_STORE_PATH = /data/multi-domain-graph-6/datasets/datasets_preproc_ens_iter1_epoch_10_test_dev/taskonomy/tiny-train_0.15/part1
                        /data/multi-domain-graph-6/datasets/datasets_preproc_ens_iter1_epoch_10_test_dev/taskonomy/tiny-train_0.15/part2
ITER2_TRAIN_SRC_PATH = /data/multi-domain-graph-3/datasets/datasets_preproc_exp/taskonomy/tiny-train_0.15/part1
                        /data/multi-domain-graph-3/datasets/datasets_preproc_exp/taskonomy/tiny-train_0.15/part2
ITER2_TRAIN_DST_PATH = /data/multi-domain-graph-3/datasets/datasets_preproc_exp/taskonomy/tiny-train_0.15/part1
                        /data/multi-domain-graph-3/datasets/datasets_preproc_exp/taskonomy/tiny-train_0.15/part2
ITER2_TRAIN_PATTERNS = /*
ITER2_TRAIN_FIRST_K = 100

ITER2_VALID_STORE_PATH = /data/multi-domain-graph-6/datasets/datasets_preproc_ens_iter1_epoch_10_test_dev/taskonomy/tiny-val-ok
ITER2_VALID_SRC_PATH = 
ITER2_VALID_DST_PATH = 
ITER2_VALID_PATTERNS = 
ITER2_VALID_FIRST_K = 

ITER2_TEST_STORE_PATH = /data/multi-domain-graph-6/datasets/datasets_preproc_ens_iter1_epoch_10_test_dev/taskonomy/tiny-test-ok
ITER2_TEST_SRC_PATH = 
ITER2_TEST_DST_PATH = 
ITER2_TEST_GT_DST_PATH = 
ITER2_TEST_PATTERNS = 
ITER2_TEST_FIRST_K = 

; ideally we can continue with as many paths as necessary [PathsIter3], [PathsIter4]


[Logs]
csv_results = csv_results
tensorboard_dir = runs/runs_dev/
tensorboard_prefix = to_depth_gen_ensembles
silent = no
csv_results_dir = csv_results_elena/

[Edge Models]
start_epoch = 10
n_epochs = 10
load_path = /data/multi-domain-graph/models/final/trained_1feb_elena
save_path = /data/multi-domain-graph/models/ema
save_epochs_distance = 5
save_models = yes


[Testing]
test_1hop_edges = no
test_min_epoch = 5
test_epoch_step = 5
test_max_epoch = 5


[Training]
train_basic_edges = no
drop_version = -1
eval_test_during_train = no


optimizer = sgd
learning_rate = 5e-2
weight_decay = 1e-3
momentum = 0.9
nesterov = true
amsgrad = true
reduce_lr_patience = 10
reduce_lr_factor = 1e-1
reduce_lr_threshold = 1e-3
reduce_lr_min_lr = 5e-5

[Training2Iters]
; 1. Run eval on trainingset2 (VALID_PATH) + save outputs
train_2_iters = no

[Ensemble]
; similarity_fct:
;       ssim
;       l1
;       equal 
;       psnr
;       lpips
;       mssim
similarity_fct = ssim
