[Run id]
datetime = 

[General]
n_iters = 2
WORKING_W = 256
WORKING_H = 256
CACHE_NAME = my_cache_replica_train_iter2
; for iter >1, what to choose as src 
; 1 - use initial experts
; 2 - use ensembles / updated experts
iters_config = 2


Steps_Iter1_train = no
Steps_Iter1_test = no
Steps_Iter1_saveNextIter = no 
Steps_Iter2_train = yes
Steps_Iter2_test = no
Steps_Iter2_saveNextIter = no 

DATASET_NAME = replica

[Experts]
# 0. RGBModel(full_experts),
# 1. DepthModelXTC(full_experts),
# 2. SurfaceNormalsXTC(full_experts),
# 3. EdgesModel(full_experts),
# 4. HalftoneModel(full_experts, 0),
# 5. SSegHRNet
# 6. Grayscale(full_experts),
# 7. HSVExpert(full_experts),
# 8. CartoonWB(full_experts),
# 9. SobelEdgesExpertSigmaLarge(full_experts),
# 10. SobelEdgesExpertSigmaMedium(full_experts),
# 11. SobelEdgesExpertSigmaSmall(full_experts),
# 12. SuperPixel(full_experts),

; selector_map = 2, 0, 1, 3, 4, 5, 6
; selector_map = 2, 7, 8, 9, 10, 11, 12
; selector_map = 4, 0, 1, 2, 3, 5, 6
; selector_map = 4, 7, 8, 9, 10, 11, 12
; selector_map = 7, 0, 1, 2, 3, 4, 5
; selector_map = 7, 6, 8, 9, 10, 11, 12
          
[GraphStructure]
; restricted_graph_type [0/1/2/3] - 0 - no restriction => all experts from selector_map above
;                                 - 1 - keep only edges with source == restricted_graph_exp_identifier
;                                 - 2 - keep only edges with destination == restricted_graph_exp_identifier
;                                 - 3 - keep only edges with source == restricted_graph_exp_identifier or destination==restricted_graph_exp_identifier
restricted_graph_type = 2 
restricted_graph_exp_identifier = depth_n_1_xtc

[PathsIter1]
; SPLIT can be TRAIN, VALID or TEST
; SPLIT_SRC_PATH = path_1
;       path_2
;       ...
;       path_n
; SPLIT_DST_PATH = path_1
;       path_2
;       ...
;       path_n
; SPLIT_PATTERNS = pattern_1
;       pattern_2 
;       ...
;       path_m
; m [1 or n] - if 1 => same pattern for all n input paths 
;            - if n => individual pattern for each of the n input paths 
;            - otherwise => multiple patterns for each of the n input paths 
; SPLIT_FIRST_K = nr
; nr - (-1) => all samples
;    - 0 => empty dataset 
;    - otherwise => nr samples
; for store purpose => will get first k from each subset
ITER1_TRAIN_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/train
ITER1_TRAIN_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/train
ITER1_TRAIN_PATTERNS = /*
ITER1_TRAIN_FIRST_K = -1

ITER1_VALID_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/val
ITER1_VALID_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/val
ITER1_VALID_PATTERNS = /*
ITER1_VALID_FIRST_K = -1

ITER1_TEST_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/test
ITER1_TEST_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/test
ITER1_TEST_GT_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_gt/replica/test
ITER1_TEST_PATTERNS = /*
ITER1_TEST_FIRST_K = -1

[PathsIter2]
; SPLIT can be TRAIN, VALID or TEST
; NEXT_ITER_SPLIT_STORE_PATH should have the same nr of elements as NEXT_ITER_SPLIT_SRC_PATH & NEXT_ITER_SPLIT_DST_PATH
; same conventions as for 'Paths'
; if NEXT_ITER_SPLIT_TYPE is empty => will get value of SPLIT_TYPE from 'Paths', for SPLIT in {TRAIN, VALID, TEST} and TYPE in {SRC_PATH, DST_PATH, PATTERNS, FIRST_K}
;    exception for TYPE=STORE_PATH - which is required 
ITER2_TRAIN_STORE_PATH = /data/multi-domain-graph-4/datasets/datasets_preproc_ens_iter1/replica/train
                        /data/multi-domain-graph-4/datasets/datasets_preproc_ens_iter1/replica_2/train
ITER2_TRAIN_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/train
                    /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica_2/train
ITER2_TRAIN_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/train
                    /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica_2/train
ITER2_TRAIN_PATTERNS = /*
ITER2_TRAIN_FIRST_K = -1

ITER2_VALID_STORE_PATH = /data/multi-domain-graph-4/datasets/datasets_preproc_ens_iter1/replica/val
ITER2_VALID_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/val
ITER2_VALID_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/val
ITER2_VALID_PATTERNS = /*
ITER2_VALID_FIRST_K = 100

ITER2_TEST_STORE_PATH = /data/multi-domain-graph-4/datasets/datasets_preproc_ens_iter1/replica/test
ITER2_TEST_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/test
ITER2_TEST_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/test
ITER2_TEST_GT_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_gt/replica/test
ITER2_TEST_PATTERNS = /*
ITER2_TEST_FIRST_K = 100

; ideally we can continue with as many paths as necessary [PathsIter3], [PathsIter4]


[Logs]
csv_results = csv_results
tensorboard_dir = runs/runs_replica_train_iter2
tensorboard_prefix = replica_train_iter2
silent = no

[Edge Models]
# 0 -> good 1M params
# 1 -> medium 4M params
model_type = 1

classif_losses = cross_entropy
classif_losses_weights = 1

regression_losses = l2, ssim
regression_losses_weights = 1, 1

smoothl1_beta = 0.2
ssim_loss_kernel = 11 

start_epoch = 0
n_epochs = 100
load_path = /data/multi-domain-graph/models/
save_path = /data/multi-domain-graph/models/replica_iter2_all_thesasme
save_epochs_distance = 10
save_models = yes


[Training]
eval_test_during_train = no


optimizer = sgd
learning_rate = 5e-2
weight_decay = 1e-3
momentum = 0.9
nesterov = true
amsgrad = true
reduce_lr_patience = 10
reduce_lr_factor = 5e-1
reduce_lr_threshold = 1e-2
reduce_lr_min_lr = 5e-5



[Ensemble]
enable_simple_mean = no 
enable_simple_median = no

; similarity_fct:
;       ssim
;       l1
;       l2
;       equal 
;       psnr
;       lpips
;       mssim
similarity_fct = lpips

# flat 
# flat_weighted 
# gauss
kernel_fct = flat_weighted

meanshiftiter_thresholds = 1
comb_type = median

fix_variance = no
variance_dismiss_threshold = 0.1

# should not be enabled together with the analysis logs below 
# if enabled, analysis will erroneous log all the runs 
#eval_top_edges_nr = 5, 10 

[Analysis]
LOGS_PATH = /root/logs_analysis
prefix = test
silent = yes