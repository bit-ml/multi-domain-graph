[Run id]
datetime = 

[General]
n_iters = 1
WORKING_W = 256
WORKING_H = 256
CACHE_NAME = my_cache_taskonomy
; for iter >1, what to choose as src 
; 1 - use initial experts
; 2 - use ensembles / updated experts
iters_config = 1

DATASET_NAME = taskonomy
; DATASET_NAME = replica

[Experts]
# 0. RGBModel(full_experts),
# 1. DepthModelXTC(full_experts),
# 2. SurfaceNormalsXTC(full_experts),
# 3. EdgesModel(full_experts),
# 4. HalftoneModel(full_experts, 0),
# 5. SSegHRNet
# 6. Grayscale(full_experts)
; selector_map = 0, 2, 1, 3

[GraphStructure]
; restricted_graph_type [0/1/2/3] - 0 - no restriction => all experts from selector_map above
;                                 - 1 - keep only edges with source == restricted_graph_exp_identifier
;                                 - 2 - keep only edges with destination == restricted_graph_exp_identifier
;                                 - 3 - keep only edges with source == restricted_graph_exp_identifier or destination==restricted_graph_exp_identifier
restricted_graph_type = 2 
restricted_graph_exp_identifier = depth_xtc

[PathsIter1]
; SPLIT can be TRAIN, VALID or TEST
; SPLIT_SRC_PATH = path_1
;       path_2
;       ...
;       path_n
; SPLIT_DST_PATH = path_1
;       path_2
;       ...
;       path_n
; SPLIT_PATTERNS = pattern_1
;       pattern_2 
;       ...
;       path_m
; m [1 or n] - if 1 => same pattern for all n input paths 
;            - if n => individual pattern for each of the n input paths 
;            - otherwise => multiple patterns for each of the n input paths 
; SPLIT_FIRST_K = nr
; nr - (-1) => all samples
;    - 0 => empty dataset 
;    - otherwise => nr samples
; for store purpose => will get first k from each subset
ITER1_TRAIN_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-train-0.15-part1
ITER1_TRAIN_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-train-0.15-part1
ITER1_TRAIN_PATTERNS = /*
ITER1_TRAIN_FIRST_K = 10

ITER1_VALID_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-val
ITER1_VALID_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-val
ITER1_VALID_PATTERNS = /*
ITER1_VALID_FIRST_K = 10

ITER1_TEST_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-test
ITER1_TEST_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-test
ITER1_TEST_GT_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_gt/taskonomy/tiny-test
ITER1_TEST_PATTERNS = /*
ITER1_TEST_FIRST_K = -1

; ITER1_TRAIN_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/train
; ITER1_TRAIN_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/train
; ITER1_TRAIN_PATTERNS = /*
; ITER1_TRAIN_FIRST_K = 10

; ITER1_VALID_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/val
; ITER1_VALID_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/val
; ITER1_VALID_PATTERNS = /*
; ITER1_VALID_FIRST_K = 10

; ITER1_TEST_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/test
; ITER1_TEST_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/test
; ITER1_TEST_GT_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_gt/replica/test
; ITER1_TEST_PATTERNS = /*
; ITER1_TEST_FIRST_K = 10


[PathsIter2]
; SPLIT can be TRAIN, VALID or TEST
; NEXT_ITER_SPLIT_STORE_PATH should have the same nr of elements as NEXT_ITER_SPLIT_SRC_PATH & NEXT_ITER_SPLIT_DST_PATH
; same conventions as for 'Paths'
; if NEXT_ITER_SPLIT_TYPE is empty => will get value of SPLIT_TYPE from 'Paths', for SPLIT in {TRAIN, VALID, TEST} and TYPE in {SRC_PATH, DST_PATH, PATTERNS, FIRST_K}
;    exception for TYPE=STORE_PATH - which is required 
ITER2_TRAIN_STORE_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-train-0.15-part1
                        /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-train-0.15-part2
ITER2_TRAIN_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-train-0.15-part1
                        /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-train-0.15-part2
ITER2_TRAIN_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-train-0.15-part1
                        /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-train-0.15-part2
ITER2_TRAIN_PATTERNS = /*
ITER2_TRAIN_FIRST_K = 100

ITER2_VALID_STORE_PATH = /data/multi-domain-graph-5/datasets/datasets_preproc_ens_iter1_elena/taskonomy/tiny-val
ITER2_VALID_SRC_PATH = 
ITER2_VALID_DST_PATH = 
ITER2_VALID_PATTERNS = 
ITER2_VALID_FIRST_K = 

ITER2_TEST_STORE_PATH = /data/multi-domain-graph-5/datasets/datasets_preproc_ens_iter1_elena/taskonomy/tiny-test
ITER2_TEST_SRC_PATH = 
ITER2_TEST_DST_PATH = 
ITER2_TEST_GT_DST_PATH = 
ITER2_TEST_PATTERNS = 
ITER2_TEST_FIRST_K = 

; ideally we can continue with as many paths as necessary [PathsIter3], [PathsIter4]

[Logs]
csv_results = csv_results
tensorboard_dir = runs/taskonomy/
tensorboard_prefix = taskonomy_iter1_eval
silent = no
csv_results_dir = csv_results_elena/


[Edge Models]
start_epoch = 20
n_epochs = 20
load_path = /data/multi-domain-graph/models/elena/tasko_iter1
save_path = /data/multi-domain-graph/models/elena/
save_epochs_distance = 5
save_models = yes


[Testing]
test_1hop_edges = yes
test_min_epoch = 20
test_epoch_step = 5
test_max_epoch = 20


[Training]
train_basic_edges = no
drop_version = -1
eval_test_during_train = no


optimizer = sgd
learning_rate = 5e-2
weight_decay = 1e-3
momentum = 0.9
nesterov = true
amsgrad = true
reduce_lr_patience = 5
reduce_lr_factor = 1e-1
reduce_lr_threshold = 1e-3
reduce_lr_min_lr = 5e-5

[Training2Iters]
; 1. Run eval on trainingset2 (VALID_PATH) + save outputs
train_2_iters = no

[Ensemble]
; similarity_fct:
;       ssim
;       l1
;       equal 
;       psnr
;       lpips
;       mssim
similarity_fct = ssim
