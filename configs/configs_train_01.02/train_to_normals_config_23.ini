[Run id]
datetime = 


[Paths]
TRAIN_PATH = /data/multi-domain-graph-3/datasets/datasets_preproc_exp/taskonomy/tiny-train_0.15/part1
TRAIN_PATTERNS = /*
FIRST_K_TRAIN = -1

VALID_PATH = /data/multi-domain-graph-3/datasets/datasets_preproc_exp/taskonomy/tiny-val-ok
VALID_PATTERNS = /*
FIRST_K_VAL = -1

; tiny-taskonomy
; VALID_PATTERNS = /*

; GOT-10k
; PATTERNS = /*/*00001

; GOT-10k_samples
; PATTERNS = /*/00000001_*, /*/00000004_*, /*/00000007_*, /*/00000010_*

EXPERTS_OUTPUT_PATH_TEST = /data/multi-domain-graph-3/datasets/datasets_preproc_exp
PREPROC_GT_PATH_TEST = /data/multi-domain-graph-3/datasets/datasets_preproc_gt
TEST_PATH = taskonomy/tiny-test-ok
TEST_PATTERNS = /*
FIRST_K_TEST = -1


;EXPERTS_OUTPUT_PATH_TEST = /data/multi-domain-graph-3/datasets/datasets_preproc_exp
;PREPROC_GT_PATH_TEST = /data/multi-domain-graph-3/datasets/datasets_preproc_ens_iter1
;TEST_PATH = taskonomy/tiny-train_0.15/part2


[Logs]
csv_results = csv_results
tensorboard_dir = runs/runs_train_01.02/
tensorboard_prefix = train_01.02_to_normals_config23
silent = no
csv_results_dir = csv_results_elena/


[Edge Models]
start_epoch = 0
n_epochs = 40
;load_path = /data/multi-domain-graph/models/trained_27ian_minlr1e-3_1e-2wd_plateau_0.02_0-40epochs
load_path = /data/multi-domain-graph/models/tests_28.01_ema/to_edges/edges_config4
save_path = /data/multi-domain-graph/models/ema
save_epochs_distance = 5
save_models = yes


[Preprocess]


[Testing]
test_1hop_edges = no
test_min_epoch = 5
test_epoch_step = 5
test_max_epoch = 40


[Training]
train_basic_edges = yes
drop_version = -1
eval_test_during_train = no
restr_src_domain = no
src_domain_restr = halftone_gray
train_only_for_new_expert = no

; standard - models 27.01
;optimizer = sgd
;learning_rate = 5e-2
;weight_decay = 1e-8
;reduce_lr_patience = 5 
;reduce_lr_factor = 1e-1
;reduce_lr_threshold = 3e-2
;reduce_lr_min_lr = 5e-5
;momentum = 0.9
;amsgrad = no

; config 20
;optimizer = adam
;learning_rate = 1e-3
;weight_decay = 1e-3
;reduce_lr_patience = 5 
;reduce_lr_factor = 1e-1
;reduce_lr_threshold = 1e-2
;reduce_lr_min_lr = 1e-5
;momentum = 0.9
;amsgrad = no

; config 21
;optimizer = adam
;learning_rate = 1e-3
;weight_decay = 1e-3
;reduce_lr_patience = 5 
;reduce_lr_factor = 1e-1
;reduce_lr_threshold = 5e-3
;reduce_lr_min_lr = 1e-5
;momentum = 0.9
;amsgrad = no

; config 22
;optimizer = adam
;learning_rate = 1e-3
;weight_decay = 1e-2
;reduce_lr_patience = 5 
;reduce_lr_factor = 1e-1
;reduce_lr_threshold = 1e-2
;reduce_lr_min_lr = 1e-5
;momentum = 0.9
;amsgrad = no


; config 23
optimizer = adam
learning_rate = 1e-3
weight_decay = 1e-2
reduce_lr_patience = 5 
reduce_lr_factor = 1e-1
reduce_lr_threshold = 5e-3
reduce_lr_min_lr = 1e-5
momentum = 0.9
amsgrad = no

[Training2Iters]
; 1. Run eval on trainingset2 (VALID_PATH) + save outputs
train_2_iters = no

NEXT_ITER_SRC_TRAIN_PATH = /data/multi-domain-graph-3/datasets/datasets_preproc_exp
NEXT_ITER_DST_TRAIN_PATH = /data/multi-domain-graph-6/datasets/datasets_preproc_ens_iter1
NEXT_ITER_DB_PATH = taskonomy/tiny-train_0.15/part2
NEXT_ITER_TRAIN_PATTERNS = /*
FIRST_K_NEXT_ITER = -1

ENSEMBLE_OUTPUT_PATH_TEST = /data/multi-domain-graph-6/datasets/datasets_preproc_ens_iter1

; for iter 2, what to choose as src 
; 0 - use gt 
; 1 - use initial experts
; 2 - use ensemble 
iter_2_src_data = 2

[Ensemble]
; mean
; median
; histo
; median10
; ssim_maps_twd_exp_mean
; ssim_maps_twd_exp_median_w
; ssim_maps_twd_exp_median 
; ssim_maps_twd_exp_median_faster
; ssim_maps_twd_exp_mixed
; ssim_maps_twd_exp_mixed_nn
; ssim_maps_btw_tasks_mean
; ssim_maps_btw_tasks_median_w
; ssim_maps_btw_tasks_median
; psnr
; lpips_alex
; lpips_squeeze
;;;;; eplips?
; import elpips
; metric = elpips.Metric(elpips.elpips_vgg(batch_size=1))
; tf_distance = metric.forward(tf_image1, tf_image2)
; distance = sess.run(tf_distance)

; ensemble_fct = lpips_squeeze
; ensemble_fct = psnr
; ensemble_fct = ssim_maps_twd_exp_median_faster
ensemble_fct = ssim_maps_twd_exp_mixed_nn
use_rgb_to_tsk = yes
add_rgb_src_in_ensemble = yes
restr_dst_domain = yes
dst_domain_restr = normals
