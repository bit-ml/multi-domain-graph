[Run id]
datetime = 

[General]
n_iters = 1
WORKING_W = 256
WORKING_H = 256
CACHE_NAME = my_cache_replica
; for iter >1, what to choose as src 
; 1 - use initial experts
; 2 - use ensembles / updated experts
iters_config = 1

Steps_Iter1_train = yes
Steps_Iter1_test = no
Steps_Iter1_saveNextIter = no 
Steps_Iter2_train = no
Steps_Iter2_test = no
Steps_Iter2_saveNextIter = no 

; this will be removed - I have some logs that I would like to move into a different setup
Steps_Iter1_testEpochs = no
Steps_Iter2_testEpochs = no


; DATASET_NAME = taskonomy
DATASET_NAME = replica

[Experts]
; 0. RGBModel(full_experts),
; 1. DepthModelXTC(full_experts),
; 2. SurfaceNormalsXTC(full_experts),
; 3. EdgesModel(full_experts),
; 4. HalftoneModel(full_experts, 0),
; 5. SSegHRNet
; 6. Grayscale(full_experts)
; 7. HSVExpert(full_experts),
; 8. CartoonWB(full_experts),
; 9. SobelEdgesExpertSigmaLarge(full_experts),
; 10. SobelEdgesExpertSigmaMedium(full_experts),
; 11. SobelEdgesExpertSigmaSmall(full_experts),
; 12. SuperPixel(full_experts),

; selector_map = 4, 0, 1, 2
; selector_map = 4, 5, 6, 7
; selector_map = 4, 9, 10, 11
; selector_map = 4, 3, 8, 12

[GraphStructure]
; restricted_graph_type [0/1/2/3] - 0 - no restriction => all experts from selector_map above
;                                 - 1 - keep only edges with source == restricted_graph_exp_identifier
;                                 - 2 - keep only edges with destination == restricted_graph_exp_identifier
;                                 - 3 - keep only edges with source == restricted_graph_exp_identifier or destination==restricted_graph_exp_identifier
restricted_graph_type = 2
restricted_graph_exp_identifier = normals_xtc

[PathsIter1]

ITER1_TRAIN_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/train
ITER1_TRAIN_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/train
ITER1_TRAIN_PATTERNS = /*
ITER1_TRAIN_FIRST_K = -1

ITER1_VALID_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/val
ITER1_VALID_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/val
ITER1_VALID_PATTERNS = /*
ITER1_VALID_FIRST_K = -1

ITER1_TEST_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/test
ITER1_TEST_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/replica/test
ITER1_TEST_GT_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_gt/replica/test
ITER1_TEST_PATTERNS = /*
ITER1_TEST_FIRST_K = -1


[PathsIter2]
; SPLIT can be TRAIN, VALID or TEST
; NEXT_ITER_SPLIT_STORE_PATH should have the same nr of elements as NEXT_ITER_SPLIT_SRC_PATH & NEXT_ITER_SPLIT_DST_PATH
; same conventions as for 'Paths'
; if NEXT_ITER_SPLIT_TYPE is empty => will get value of SPLIT_TYPE from 'Paths', for SPLIT in {TRAIN, VALID, TEST} and TYPE in {SRC_PATH, DST_PATH, PATTERNS, FIRST_K}
;    exception for TYPE=STORE_PATH - which is required 
ITER2_TRAIN_STORE_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-train-0.15-part1
                        /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-train-0.15-part2
ITER2_TRAIN_SRC_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-train-0.15-part1
                        /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-train-0.15-part2
ITER2_TRAIN_DST_PATH = /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-train-0.15-part1
                        /data/multi-domain-graph-2/datasets/datasets_preproc_exp/taskonomy/tiny-train-0.15-part2
ITER2_TRAIN_PATTERNS = /*
ITER2_TRAIN_FIRST_K = 100

ITER2_VALID_STORE_PATH = /data/multi-domain-graph-5/datasets/datasets_preproc_ens_iter1_elena/taskonomy/tiny-val
ITER2_VALID_SRC_PATH = 
ITER2_VALID_DST_PATH = 
ITER2_VALID_PATTERNS = 
ITER2_VALID_FIRST_K = 

ITER2_TEST_STORE_PATH = /data/multi-domain-graph-5/datasets/datasets_preproc_ens_iter1_elena/taskonomy/tiny-test
ITER2_TEST_SRC_PATH = 
ITER2_TEST_DST_PATH = 
ITER2_TEST_GT_DST_PATH = 
ITER2_TEST_PATTERNS = 
ITER2_TEST_FIRST_K = 

; ideally we can continue with as many paths as necessary [PathsIter3], [PathsIter4]

[Logs]
csv_results = csv_results
tensorboard_dir = runs
tensorboard_prefix = replica_iter1_3martie
silent = no
csv_results_dir = csv_results_elena/


[Edge Models]
# 0 -> good 1M params
# 1 -> medium 4M params
model_type = 0

classif_losses = cross_entropy
classif_losses_weights = 1

regression_losses = l2, ssim
regression_losses_weights = 1, 1

smoothl1_beta = 0.2
ssim_loss_kernel = 11 

start_epoch = 0
n_epochs = 100
load_path = /data/multi-domain-graph/models/
save_path = /data/multi-domain-graph/models/replica_iter1_all_thesasme
save_epochs_distance = 10
save_models = yes


[Testing]
test_min_epoch = 10
test_epoch_step = 5
test_max_epoch = 10


[Training]
eval_test_during_train = no


optimizer = sgd
learning_rate = 5e-2
weight_decay = 1e-3
momentum = 0.9
nesterov = true
amsgrad = true
reduce_lr_patience = 10
reduce_lr_factor = 5e-1
reduce_lr_threshold = 1e-2
reduce_lr_min_lr = 5e-5



[Ensemble]
; similarity_fct:
;       ssim
;       l1
;       l2
;       equal 
;       psnr
;       lpips
;       mssim
similarity_fct = l1

# flat 
# flat_weighted 
# gauss
kernel_fct = flat_weighted

meanshiftiter_thresholds = 0.5
comb_type = median

fix_variance = no
variance_dismiss_threshold = 0.02

[Analysis]
LOGS_PATH = /root/logs_analysis
prefix = test
silent = yes